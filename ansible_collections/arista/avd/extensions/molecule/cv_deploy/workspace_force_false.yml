---
- name: "{{ test_id | upper }} Converge - cv_submit_workspace_force = false"
  hosts: SITE1_FABRIC:INACTIVE
  connection: local
  gather_facts: false
  vars:
    cv_server: "{{ lookup('env', 'CV_SERVER') }}"
    cv_token: "{{ lookup('env', 'CV_ACCESS_TOKEN') }}"
    proxy_host: "{{ lookup('env', 'CV_PROXY_HOST') | default('', true) }}"
    proxy_port: "{{ lookup('env', 'CV_PROXY_PORT') | default(3128, true) | int }}"
    proxy_username: "{{ lookup('env', 'CV_PROXY_USERNAME') | default('', true) }}"
    proxy_password: "{{ lookup('env', 'CV_PROXY_PASSWORD') | default('', true) }}"
    cv_verify_certs: "{{ lookup('env', 'CV_VERIFY_CERTS') | default(true, true) | bool }}"
    cv_skip_missing_devices: true
    eos_config_dir: "{{ playbook_dir }}/intended/configs/test_configs"
    structured_dir: "{{ playbook_dir }}/intended/structured_configs/test_configs"
    intended_tag_device: avd-ci-leaf1
    intended_tags: "{{ lookup('file', structured_dir ~ '/' ~ intended_tag_device ~ '.yml')| from_yaml }}"
    test_id: "inactive-device_force-ws-false"
    cv_common_pattern: "avd_cv-deploy_{{ test_id }}"

  tasks:
    - name: "{{ test_id | upper }} Banner"
      tags: ["{{ test_id }}"]
      run_once: true
      ansible.builtin.debug:
        msg:
          - "{{ ('#' * (31 + test_id | length))[:100] }}"
          - "### STARTING MOLECULE TEST {{ test_id[:69] | upper }} ###"
          - "{{ ('#' * (31 + test_id | length))[:100] }}"

    - name: "{{ test_id | upper }} {{ 'Read' if lookup('env', 'MOLECULE_EXECUTION_ID') else 'Generate' }} molecule execution ID"
      tags: ["{{ test_id }}"]
      ansible.builtin.set_fact:
        r: "{{ lookup('env', 'MOLECULE_EXECUTION_ID') or lookup('password', '/dev/null chars=ascii_lowercase,digits length=4') }}"
      run_once: true

    - name: "{{ test_id | upper }} Dynamically add inactive device avd-ci-core1 to group INACTIVE"
      tags: ["{{ test_id }}"]
      run_once: true
      ansible.legacy.add_host:
        name: avd-ci-core1
        groups: INACTIVE

    - name: "{{ test_id | upper }} Code block to provision CVP with AVD configuration"
      tags: ["{{ test_id }}"]
      run_once: true
      delegate_to: localhost

      block:

        - name: "(BLOCK) {{ test_id | upper }} Banner"
          tags: ["{{ test_id }}"]
          run_once: true
          ansible.builtin.debug:
            msg:
              - "### ENGAGE CV_DEPLOY ROLE TO PUSH CONFIGURATION FOR {{ test_id[:69] | upper }} ###"

        # This task is expected to fail
        - name: "(BLOCK) {{ test_id | upper }} Trigger errors"
          tags: ["{{ test_id }}"]
          ansible.builtin.import_role:
            name: arista.avd.cv_deploy
          vars:
            cv_workspace_name: "{{ cv_common_pattern }}_{{ r }}_converge"
            cv_workspace_description: "{{ (cv_common_pattern + '_' + r + '_converge') | upper }}"
            cv_change_control_name: "{{ cv_common_pattern }}_{{ r }}_converge"
            cv_change_control_description: "{{ (cv_common_pattern + '_' + r + '_converge') | upper }}"
            cv_register_detailed_results: true
            cv_devices: [avd-ci-leaf1, avd-ci-core1]

        # If task above did not fail for whatever reason - execute following task to catch this
        # Task below is not expected to run under normal conditions
        - name: "(BLOCK) {{ test_id | upper }} Force failure"
          tags: ["{{ test_id }}"]
          run_once: true
          ansible.builtin.fail:
            msg: "Previous task was expected to fail but something went wrong."
          register: force_failure

      rescue:

        - name: "(RESCUE) {{ test_id | upper }} Force failure"
          tags: ["{{ test_id }}"]
          run_once: true
          ansible.builtin.fail:
            msg: "Call towards CV inside BLOCK was expected to FAIL but has not. Please investigate (check EOS/CV states and streaming, etc.)."
          when: force_failure is defined

        # Clear failed state of failed hosts for next engaged playbook (no impact within running playbook)
        - name: "(RESCUE) {{ test_id | upper }} Reset ansible_play_hosts for next playbook (no impact within running playbook)"
          tags: ["{{ test_id }}"]
          ansible.builtin.meta: clear_host_errors

        - name: "(RESCUE) {{ test_id | upper }} Check CVP returns"
          tags: ["{{ test_id }}"]
          run_once: true
          ansible.builtin.assert:
            that:
              # errors and warnings
              - "'Failed to submit CloudVision Workspace due to the presence of inactive devices' in cv_deploy_results.errors[0]"
              - cv_deploy_results.workspace.state == "submit failed"

      always:

        - name: "(ALWAYS) {{ test_id | upper }} Display CVP detailed result"
          tags: ["{{ test_id }}"]
          run_once: true
          ansible.builtin.debug:
            var: cv_deploy_results

        - name: "(ALWAYS) {{ test_id | upper }} Cleanup orphan workspace"
          tags: ["{{ test_id }}"]
          run_once: true
          ansible.legacy.uri:
            url: https://{{ cv_server }}/api/resources/workspace/v1/WorkspaceConfig/some
            use_proxy: "{{ true if proxy_host and proxy_port else false }}"
            validate_certs: "{{ cv_verify_certs }}"
            return_content: true
            headers:
              Accept: "application/json"
              Content-Type: "application/json"
              Authorization: "Bearer {{ lookup('env', 'CV_ACCESS_TOKEN') }}"
            method: POST
            body_format: json
            body:
              {
                "values": [
                  {
                    "key": {
                      "workspaceId": "{{ cv_deploy_results.workspace.id }}"
                    },
                    "request": "REQUEST_ABANDON",
                    "requestParams": {
                      "requestId": "{{ r }}"
                    }
                  }
                ]
              }
            force_basic_auth: true
            timeout: 10
          register: cvp_abandon_workspace_result
          until: cvp_abandon_workspace_result.status == 200
          retries: 3
          delay: 3
          ignore_errors: true
          when: |
            cv_deploy_results.workspace.id is not none and
            cv_deploy_results.workspace.id | length > 0 and
            cv_deploy_results.workspace.state | default('') != "abandoned"
          # Set HTTPS_PROXY environment variable scoped for this task only
          environment:
            https_proxy: >-
              http://{{ (proxy_username and proxy_password) | ternary(proxy_username ~ ':' ~ proxy_password ~ '@', '') }}{{ proxy_host }}:{{ proxy_port }}

        - name: "(ALWAYS) {{ test_id | upper }} Banner"
          tags: ["{{ test_id }}"]
          run_once: true
          ansible.builtin.debug:
            msg:
              - "### ENGAGE CV_DEPLOY ROLE TO CLEANUP AFTER {{ test_id[:69] | upper }} ###"

        - name: "(ALWAYS) {{ test_id | upper }}  Cleanup"
          tags: ["{{ test_id }}"]
          run_once: true
          delegate_to: localhost
          ansible.builtin.import_role:
            name: arista.avd.cv_deploy
          vars:
            cv_workspace_name: "{{ cv_common_pattern }}_{{ r }}_cleanup"
            cv_workspace_description: "{{ (cv_common_pattern + '_' + r + '_cleanup') | upper }}"
            cv_change_control_name: "{{ cv_common_pattern }}_{{ r }}_cleanup"
            cv_change_control_description: "{{ (cv_common_pattern + '_' + r + '_cleanup') | upper }}"
            cv_register_detailed_results: true
            cv_devices: "{{ ansible_play_hosts_all }}"
            eos_config_dir: "{{ playbook_dir }}/intended/configs/base_configs"
            structured_dir: "{{ playbook_dir }}/intended/structured_configs/base_configs"
            cv_submit_workspace_force: true
            cv_run_change_control: true
